FROM python:3.11-slim

# Set environment variables
ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64


# Install system packages: Java, SSH, build tools
RUN apt-get update && apt-get install -y --no-install-recommends \
    openjdk-17-jdk-headless \
    curl wget git nano sudo \
    openssh-server \
    build-essential \
    dos2unix \
    file \
    && rm -rf /var/lib/apt/lists/*


# -------------------------------
# Setup SSH access
# -------------------------------


RUN mkdir /var/run/sshd && \
    echo 'root:root' | chpasswd && \
    sed -i 's/#PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config && \
    sed -i 's@session\s*required\s*pam_loginuid.so@session optional pam_loginuid.so@g' /etc/pam.d/sshd





# -------------------------------
# Install Apache Spark
# -------------------------------

ENV SPARK_VERSION=3.5.0
ENV HADOOP_VERSION=3

RUN wget https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz && \
    tar -xzf spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz -C /opt && \
    mv /opt/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} /opt/spark && \
    rm spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz


ENV SPARK_HOME=/opt/spark
ENV PATH="$SPARK_HOME/bin:$PATH"


# -------------------------------
# Create virtual environment
# -------------------------------

COPY workspace/sp500/utils/bootstrap_venv.sh /usr/local/bin/bootstrap_venv.sh
RUN chmod +x /usr/local/bin/bootstrap_venv.sh

ENTRYPOINT ["/usr/local/bin/bootstrap_venv.sh"]


# Expose ports: SSH, Jupyter, Spark UI
EXPOSE 22
EXPOSE 8888
EXPOSE 4040
EXPOSE 4041
EXPOSE 4042

CMD ["/usr/sbin/sshd", "-D"]
